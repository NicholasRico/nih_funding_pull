# NIH Funding Project

This project retrieves funding data from the NIH Reporter API based on user-defined search queries and fiscal years, performs topic modeling to categorize project titles, and exports the results to an Excel file with hyperlinks to project details.

## Overview

The script uses the NIH Reporter API to fetch project data, preprocesses the text of project titles using natural language processing (NLP) techniques, applies Latent Dirichlet Allocation (LDA) for topic modeling, and assigns categories to projects based on dominant topics. The output is saved as an Excel file (`NIH_Funding.xlsx`) containing detailed project information, including hyperlinks to the NIH Reporter website.

### Key Features
- Fetches NIH project data based on user-specified keywords and fiscal years.
- Preprocesses text data using tokenization, lemmatization, and stop word removal.
- Performs LDA topic modeling to identify funding categories.
- Exports results to an Excel file with hyperlinks and sanitized text for compatibility.

## Requirements

The project requires the following Python packages, listed in `requirements.txt`:
- `requests` (for API calls)
- `pandas` (for data manipulation and Excel export)
- `nltk` (for text preprocessing)
- `gensim` (for topic modeling)
- `openpyxl` (for Excel file handling)

## Installation

1. **Clone the Repository**:
   - If this is a Git repository, clone it to your local machine:


   
2. **Set Up a Virtual Environment**:
- Create a virtual environment (e.g., `myenv`):

- Activate it:
- On Windows: `myenv\Scripts\activate`
- On macOS/Linux: `source myenv/bin/activate`

3. **Install Dependencies**:
- With the virtual environment activated, install the required packages:


4. **Download NLTK Data**:
- The script automatically downloads required NLTK resources (e.g., `punkt_tab`, `stopwords`, `wordnet`) on the first run. Ensure you have an internet connection during this step.

## Usage

1. **Run the Script**:
- With the virtual environment activated, run the script:


2. **Input Prompts**:
- The script will prompt you to enter:
- **Search Keywords**: Enter keywords separated by commas (e.g., `cancer, genetics`). These are combined with `OR` for the API query.
- **Fiscal Years**: Enter a range (e.g., `2023-2025`) or a comma-separated list (e.g., `2023, 2024`).
- Example input:


3. **Confirm Data Fetch**:
- The script will display the total number of projects matching your query and ask for confirmation to proceed with fetching the data (up to a default limit of 30,000 projects, with a batch size of 500).

4. **Output**:
- After processing, the script will:
- Print the distribution of funding categories based on topic modeling.
- Save the results to `NIH_Funding.xlsx`, including project details, categories, and hyperlinks to NIH Reporter pages.

## File Structure

- `nih.py`: The main Python script containing the logic for API calls, text preprocessing, topic modeling, and Excel export.
- `requirements.txt`: Lists the required Python packages.
- `README.md`: This file, providing project documentation.
- `myenv/`: Virtual environment directory (created during setup).
- `.gitignore`: Specifies files/folders to ignore in version control (e.g., `myenv/`).

## Customization

- **Number of Topics**: Adjust the `num_topics` variable in the `perform_topic_modeling` function (default is 5) to change the number of categories generated by LDA.
- **Fetch Limits**: Modify the `limit` and `total_limit` parameters in the `fetch_data` method to control the number of projects fetched.
- **API Endpoint**: The NIH Reporter API endpoint (`https://api.reporter.nih.gov/v2/projects/search`) is hardcoded but can be updated if the API changes.

## Notes

- **API Rate Limits**: The script includes a 1-second delay between API requests to respect rate limits. Adjust `time.sleep(1)` if needed based on NIH API policies.
- **Excel Compatibility**: The script sanitizes text to remove control characters incompatible with Excel.
- **Dependencies**: Ensure all NLTK resources are downloaded successfully. If issues arise, manually download them using `nltk.download()` in a Python shell.

## Contributing

Feel free to fork this repository, submit issues, or create pull requests to improve the project. Contributions to enhance topic modeling, add more data fields, or optimize API calls are welcome!

## License

[Add your license here, e.g., MIT, GPL, etc., if applicable. If none, state that the code is provided as-is without a license.]

## Contact

For questions or support, please open an issue in the repository or contact NicholasRico.